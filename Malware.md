# Malware - Slides
Malware, or malicious software, is any program or file that is **intentionally** harmful to a computer, network or server.

## History of malware
- Creeper (1971): Creeper did no harm to the systems it infected - Thomas developed it as a proof of concept, and its only effect was that it caused connected teletype machines to print a message that said “I’M THE CREEPER: CATCH ME IF YOU CAN.”
- ILOVEYOU (2000): a worm that would steal other people’s passwords so he could piggyback off of their accounts.
- CryptoLocker (2013): a ransomware trojan that targeted computers running Windows.
- Mirai (2016): a botnet that targeted Internet of Things (IoT) devices such as routers, security cameras and DVRs.
- Clop (2019): a ransomware that encrypts files on a victim’s computer and demands a ransom to decrypt them.

## PE Files
PE files are Windows executable files.

## How to recognize malware

1. **Signature-based detection:** Identifies malware based on known digital indicators, but is reactive in nature.

2. **Static file analysis:** Examines a file's code without execution, looking for signs of malicious intent in file names, hashes, and other data.

3. **Dynamic malware analysis:** Executes suspected malicious code in a secure environment (sandbox) to observe and study malware behavior without risking infection.

4. **Dynamic monitoring of mass file operations:** Observes mass file operations for signs of tampering or corruption, utilizing file integrity monitoring tools.

5. **File extensions blocklist:** Prevents the download or use of dangerous files by listing known malicious file extensions.

6. **Application allowlist:** Authorizes approved applications, reducing the risk of nefarious applications but potentially impacting operational speed and flexibility.

7. **Malware honeypot:** Simulates a safe environment to draw out and analyze malware attacks, aiding in the development of antimalware solutions.

8. **Cyclic redundancy check (CRC):** Checks data integrity through calculations, though it is not foolproof against tampering.

9.  **File entropy:** Identifies potential malware by measuring data changes in files, particularly those with high entropy levels.

10. **Machine learning analysis:** Uses machine learning algorithms to analyze file behavior, identify patterns, and improve detection of novel and unidentified malware.

## Malware Detection
The collected data used to malware recognition is collected at different phases:
- **Pre-execution phase data**: Information about a file obtained without executing it. This includes details such as executable file format, code descriptions, binary data statistics, text strings, and information extracted through code emulation. Essentially, it encompasses everything known about a file before it is run.

- **Post-execution phase data**: Information that reveals the behavior or events resulting from a file's activity within a system. This data is collected after the file has been executed and provides insights into the consequences of the file's actions on the system.

## Machine learning approaches

- **Unsupervised learning**: Large unlabeled datasets are available to cybersecurity vendors and the cost of their manual labeling by experts is high.
- **Supervised learning**: The goal is to fit the
model that will produce the right answers for new objects. This approach consists of two stages, traning the model and fitting the model and applying the trained model to new samples.

Note: X could be some features of the file, and y could be the label of the file (malware or benign).

## Requirements

- Deep Learning is a special machine learning approach that facilitates the extraction of features of a high level of abstraction from low-level data;
- Large representative datasets;
- The trained model has to be interpretable (XAI): most model families used are called **black box models**. They are given the input X, and they will produce Y through a complex sequence of operations that can hardly be interpreted by a human.
- False positive rates must be low.
- Model must be able to adapt to new malware families and new benign software.

## Multi-class classification
Multi-class classification is the problem of
classifying instances into one of **three or more classes**.

### One-vs-Rest (One-vs-All)
Splits the multi-class dataset into multiple binary classification problems and uses them to train the binary classifier and predict the results.

Example: 
- Binary Classification Problem 1: red vs [blue, green]
- Binary Classification Problem 2: blue vs [red, green]
- Binary Classification Problem 3: green vs [red, blue]

### One-vs-one
It involves fitting one binary classifier **per class pair**. If there are N classes in the dataset, then there are `N * (N - 1) / 2` binary classifiers that are trained.

Example:
- Binary Classification Problem 1: red vs. blue
- Binary Classification Problem 2: red vs. green
- Binary Classification Problem 3: red vs. yellow
- Binary Classification Problem 4: blue vs. green
- Binary Classification Problem 5: blue vs. yellow
- Binary Classification Problem 6: green vs. yellow

# Malware - Notebooks

## Libraries

### Pandas library
The **iloc function** is part of pandas and is used as an indexing tool for csv datasets, first argument is the row and second argument is the column `df.iloc[row, column].values`.

### Scikit-learn library
*Imputer* is a transformer for completing missing values, it replaces missing values with the mean value of the column.

## Classes Distribution
The classes distribution is the number of samples for each class.

## Features visualization
The features visualization is the number of features for each class.

## Feature Scaling
Feature scaling is a method used to normalize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step.

## Keras Classifier
Keras works by creating a neural network model, compiling it with an optimizer and loss function, training it on labeled data, and then using the trained model to make predictions on new data.

## Evaluation Metrics

### Confusion Matrix
It´s composed of 4 different values:
- True Positive (TP): the model correctly predicts the positive class.
- True Negative (TN): the model correctly predicts the negative class.
- False Positive (FP): the model incorrectly predicts the positive class.
- False Negative (FN): the model incorrectly predicts the negative class.

### Accuracy
Accuracy is the ratio of correctly predicted observation to the total observations `TP + TN / TP + TN + FP + FN`

### Precision
Precision is the ratio of correctly predicted positive observations to the total predicted positive observations `TP / TP + FP`

### Recall
Recall is the ratio of correctly predicted positive observations to the all observations in actual class `TP / TP + FN`

### F1-score
F1-score is the weighted average of Precision and Recall (2 * Precision * Recall / Precision + Recall)

### Squared Error
Squared error is the difference between the predicted value and the actual value, squared.

### MCC
MCC is the correlation coefficient between the observed and predicted binary classifications. It returns a value between -1 and 1. A coefficient of +1 represents a perfect prediction, 0 represents a random prediction and -1 represents an inverse prediction.

### ROC curve
ROC curve is a plot of the true positive rate (TPR) against the false positive rate (FPR) for the different possible cutpoints of a diagnostic test.

The area under the curve (AUC) is a measure of how well a parameter can distinguish between two diagnostic groups, if the AUC is 0.5, the parameter is totally random, if the AUC is 1, the parameter is perfect.

### Loss curves (Training and Validation)
The loss function is a measure of how well a machine learning model is able to predict the expected outcome. The lower the loss function, the better the model is at predicting the outcome.

### Mcnemar's Test
McNemar test should be used for obtaining a probability of difference between the cases of false negative and false positives, to **compare two classifiers**.

It's a 2x2 matrix:
- A: both models predict correctly
- B: model 1 predicts correctly, model 2 predicts incorrectly
- C: model 1 predicts incorrectly, model 2 predicts correctly
- D: both models predict incorrectly

P-value is the probability of obtaining a test statistic at least as extreme as the one that was actually observed, assuming that the null hypothesis is true. if the p-value is less than the significance level, there is a significant difference between the two classifiers.

### Feature Importance
Feature importance assigns a score to input features based on how useful they are at predicting a target variable.

In each model:
- Logistic Regression: the coefficients of the model;
- Decision Tree: importance scores based on the reduction in the criterion used to select split points, like Gini or entropy;
- CART (Classification and Regression Trees): after being fit, the model provides a feature importances property;